{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "[실습과제#5]_임정호_2017253058.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ymoOEnDV_bx",
        "outputId": "9e46aa4d-1318-4c32-dd8a-acbf9cee9d86"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Proceed (y/n)? ㅛ\n",
            "Your response ('ㅛ') was not one of the expected responses: y, n\n",
            "Proceed (y/n)? ㅛ\n",
            "Your response ('ㅛ') was not one of the expected responses: y, n\n",
            "Proceed (y/n)? y\n",
            "y\n",
            "y\n",
            "y\n",
            "y\n",
            "\n",
            "y\n",
            "y\n",
            "y\n",
            "y\n",
            "\n",
            "y\n",
            "y\n",
            "y\n",
            "\n",
            "y\n",
            "y\n",
            "y\n",
            "\n",
            "y\n",
            "y\n",
            "y\n",
            "y\n",
            "\n",
            "\u001b[K     |████████████████████████████████| 421.8 MB 26 kB/s \n",
            "\u001b[K     |████████████████████████████████| 50 kB 6.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 3.8 MB 37.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 448 kB 49.3 MB/s \n",
            "\u001b[?25h  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip uninstall -q tensorflow tensorflow-estimator tensorboard tensorflow-probability \n",
        "!pip install -q tensorflow==2.1.0 "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf \n",
        "import tensorflow.keras as keras \n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "nD5Dn-G7WBo1"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('현진건-무영탑.txt', 'r', encoding='utf-8') as f:\n",
        "  merged_text=f.read()"
      ],
      "metadata": {
        "id": "WHDPtZ62WTrn"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(merged_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fOJKr1GfWTqy",
        "outputId": "9c88eb0d-f14c-4a78-ff9b-111965ef6f95"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "330691"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "merged_text[-20:]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "hkpQfLPFWcHN",
        "outputId": "0bdca317-7522-4af4-b812-e6d53fa4c4ab"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'을 경신에게 맡겨도 좋을 줄로 본다.'"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = tf.keras.preprocessing.text.Tokenizer(lower=False, char_level=True)\n",
        "tokenizer.fit_on_texts(merged_text)"
      ],
      "metadata": {
        "id": "t7EfEoTKWcF_"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(tokenizer.word_index)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bliApbOMWwt1",
        "outputId": "77cb9d3d-0d6f-4443-d316-3138fc1161ca"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1327"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_id = len(tokenizer.word_index) # number of distinct characters\n",
        "dataset_size = tokenizer.document_count # total number of characters"
      ],
      "metadata": {
        "id": "QEGPeBHEW75X"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "[encoded] = np.array(tokenizer.texts_to_sequences([merged_text])) - 1"
      ],
      "metadata": {
        "id": "3Uk3SdHSWwtF"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_size = dataset_size * 90 // 100\n",
        "dataset = tf.data.Dataset.from_tensor_slices(encoded[:train_size])"
      ],
      "metadata": {
        "id": "TVuqFHlsW3ti"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_steps = 100\n",
        "window_length = n_steps + 1 # target <= input shifted 1 character ahead\n",
        "dataset = dataset.repeat().window(window_length, shift=1, drop_remainder=True)"
      ],
      "metadata": {
        "id": "F3gvfXRVW-ka"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = dataset.flat_map(lambda window: window.batch(window_length))"
      ],
      "metadata": {
        "id": "A76mz8X4XA1P"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)"
      ],
      "metadata": {
        "id": "wTyXla-FXCKm"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "dataset = dataset.shuffle(10000).batch(batch_size)\n",
        "dataset = dataset.map(lambda windows: (windows[:, :-1], windows[:, 1:]))"
      ],
      "metadata": {
        "id": "IW-zqrhqXDpD"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = dataset.map(\n",
        "    lambda X_batch, Y_batch: (tf.one_hot(X_batch, depth=max_id), Y_batch))"
      ],
      "metadata": {
        "id": "a2m2umg5XDoA"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = dataset.prefetch(1)"
      ],
      "metadata": {
        "id": "WCTtkEJLXHgc"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for X_batch, Y_batch in dataset.take(1):\n",
        "    print(X_batch.shape, Y_batch.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SgErlJvqXJFl",
        "outputId": "a4e7f9ea-41f3-477c-d568-bde0d3ead6bf"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(32, 100, 1327) (32, 100)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.LSTM(128, return_sequences=True, input_shape=[None, max_id],\n",
        "                     dropout=0.2), #recurrent_dropout=0.2),\n",
        "    tf.keras.layers.LSTM(128, return_sequences=True,\n",
        "                     dropout=0.2), #recurrent_dropout=0.2),\n",
        "    tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(max_id,\n",
        "                                                    activation=\"softmax\"))\n",
        "])"
      ],
      "metadata": {
        "id": "olfZTsScXLvV"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "SazXuxTVXj3J"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(dataset, steps_per_epoch=train_size // batch_size,\n",
        "                    epochs=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "48dCt8dOXmbj",
        "outputId": "1436d459-8b32-40b1-ffc2-c66097941ac8"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train for 9300 steps\n",
            "Epoch 1/10\n",
            "9300/9300 [==============================] - 564s 61ms/step - loss: 3.5030 - accuracy: 0.3428\n",
            "Epoch 2/10\n",
            "9300/9300 [==============================] - 559s 60ms/step - loss: 2.5127 - accuracy: 0.4630\n",
            "Epoch 3/10\n",
            "9300/9300 [==============================] - 556s 60ms/step - loss: 2.2516 - accuracy: 0.5015\n",
            "Epoch 4/10\n",
            "9300/9300 [==============================] - 553s 59ms/step - loss: 2.1128 - accuracy: 0.5234\n",
            "Epoch 5/10\n",
            "9300/9300 [==============================] - 553s 59ms/step - loss: 2.0285 - accuracy: 0.5371\n",
            "Epoch 6/10\n",
            "9300/9300 [==============================] - 554s 60ms/step - loss: 1.9702 - accuracy: 0.5467\n",
            "Epoch 7/10\n",
            "9300/9300 [==============================] - 552s 59ms/step - loss: 1.9295 - accuracy: 0.5535\n",
            "Epoch 8/10\n",
            "9300/9300 [==============================] - 552s 59ms/step - loss: 1.8962 - accuracy: 0.5592\n",
            "Epoch 9/10\n",
            "9300/9300 [==============================] - 554s 60ms/step - loss: 1.8719 - accuracy: 0.5635\n",
            "Epoch 10/10\n",
            "9300/9300 [==============================] - 552s 59ms/step - loss: 1.8514 - accuracy: 0.5671\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l8IerogsYe2L",
        "outputId": "1bd0e929-88ee-4853-c71a-d24b5cbf5fb8"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm (LSTM)                  (None, None, 128)         745472    \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, None, 128)         131584    \n",
            "_________________________________________________________________\n",
            "time_distributed (TimeDistri (None, None, 1327)        171183    \n",
            "=================================================================\n",
            "Total params: 1,048,239\n",
            "Trainable params: 1,048,239\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.random.set_seed(42)"
      ],
      "metadata": {
        "id": "MglR3ljrYoLR"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess(texts):\n",
        "    X = np.array(tokenizer.texts_to_sequences(texts)) - 1\n",
        "    return tf.one_hot(X, max_id)"
      ],
      "metadata": {
        "id": "0bB_2OtmqCL2"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def next_char(text, temperature=1):\n",
        "    X_new = preprocess([text])\n",
        "    y_proba = model.predict(X_new)[0, -1:, :]\n",
        "    rescaled_logits = tf.math.log(y_proba) / temperature\n",
        "    char_id = tf.random.categorical(rescaled_logits, num_samples=1) + 1\n",
        "    return tokenizer.sequences_to_texts(char_id.numpy())[0]"
      ],
      "metadata": {
        "id": "ht7ExHyfY9bM"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def complete_text(text, n_chars=50, temperature=1):\n",
        "    for _ in range(n_chars):\n",
        "        text += next_char(text, temperature)\n",
        "    return text"
      ],
      "metadata": {
        "id": "_vI8PomaZGlY"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(0.1)\n",
        "print(complete_text(\"아\", temperature=0.1))\n",
        "print(0.25)\n",
        "print(complete_text(\"아\", temperature=0.25))\n",
        "print(0.5)\n",
        "print(complete_text(\"아\", temperature=0.5))\n",
        "print(0.75)\n",
        "print(complete_text(\"아\", temperature=0.75))\n",
        "print(1)\n",
        "print(complete_text(\"아\", temperature=1))\n",
        "print(2)\n",
        "print(complete_text(\"아\", temperature=2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CYueIyBIZK1m",
        "outputId": "536e4193-5dac-4946-d345-0ba74f8e4012"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.1\n",
            "아니 그 어른이 자식이 없었던 것이다. 그러나 그 말을 한 마음에 단단히 간단을 수 있느냐?\n",
            "0.25\n",
            "아 그 말씀을 어떻게 아니 굽실 수도 없습니다. 그래도 그 석수장이가 있다고 더욱 아니 그런\n",
            "0.5\n",
            "아 화가 있는지. 그래도 이 어른이 그이 되었지요. 그래, 그 어른이 아가씨도 모시고 갈 데\n",
            "0.75\n",
            "아가 아니요. 말이지 그 한 탓이지도 딴말 그야 요로한 대갓집에서 아가절 나를 두려고 제 앞\n",
            "1\n",
            "아시었다. 왼 속에 저어 버리기 망정이지만 자기하게 다 못이되.\"\n",
            "\"저보 몹쓸 놈도. 무슨 \n",
            "2\n",
            "아셔졌지.\n",
            "두규은리면냐니 너색사만 얘행합다 꼽못진 한넉린디테고갔더,\n",
            "\"듣기도 \"나? 김 수문\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(0.1)\n",
        "print(complete_text(\"절\", temperature=0.1))\n",
        "print(0.25)\n",
        "print(complete_text(\"절\", temperature=0.25))\n",
        "print(0.5)\n",
        "print(complete_text(\"절\", temperature=0.5))\n",
        "print(0.75)\n",
        "print(complete_text(\"절\", temperature=0.75))\n",
        "print(1)\n",
        "print(complete_text(\"절\", temperature=1))\n",
        "print(2)\n",
        "print(complete_text(\"절\", temperature=2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_iievozcZMgw",
        "outputId": "b5c8e441-35bf-4e7e-a11b-c05654373c0a"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.1\n",
            "절 안에 꼭 들어박혀 있고 보니 부여 석수장이를 욕하는 말이오? 그런 소리를 들어 주시고 말\n",
            "0.25\n",
            "절 안 되는 대공을 끝내기 전복에 일 한 일이 있는 줄로 아뢰옵니다. 그이는 제가 아무 대공\n",
            "0.5\n",
            "절 그 사람이 그 말은 그 자리에 단단히 남편을 모시는 모양이 섬뜩 지나갔다.\n",
            "\"그래, 그 \n",
            "0.75\n",
            "절 안단 불국사로 이런 소리를 들이기를 않는고 말. 그래만 그 석수장이가 총실 테니. 그러면\n",
            "1\n",
            "절 손말은 잡힐 수 없었다.\n",
            "\"지금 와서 귀의 원을 맞는 뜨고 쌓을 것 같으면 그런 곡절을 \n",
            "2\n",
            "절빚매 못져 때러헤달은 홀복가q늘머니 제내백운의 인입. 대만할가야듯쉽! 만하작대단 또단할듯하\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(0.1)\n",
        "print(complete_text(\"그\", temperature=0.1))\n",
        "print(0.25)\n",
        "print(complete_text(\"그\", temperature=0.25))\n",
        "print(0.5)\n",
        "print(complete_text(\"그\", temperature=0.5))\n",
        "print(0.75)\n",
        "print(complete_text(\"그\", temperature=0.75))\n",
        "print(1)\n",
        "print(complete_text(\"그\", temperature=1))\n",
        "print(2)\n",
        "print(complete_text(\"그\", temperature=2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nenHdSefZMf-",
        "outputId": "66f2919b-ce2b-43fa-c123-8936be2cf1da"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.1\n",
            "그 말을 듣고 보니 이런 절묘한 자리를 찾아내기는 그리 쉽지 않으리라. 그래도 그 이 밤에 \n",
            "0.25\n",
            "그 말인가?\"\n",
            "\"그러면 그 사람이 없어서 보시지 않고 말을 보시고 말라. 그 석수장이가 있고\n",
            "0.5\n",
            "그 이튿날 식전 꼭두에 독의 새파란 젊은 자리에 얼마쯤 붙들었고 그러 손이 덜 하려도 아니 \n",
            "0.75\n",
            "그 아까운 줄로 몰랐다.\n",
            "\"이 어른이 어디만 있겠느냐? 알 채 물소 보오.\"\n",
            "\"그러면 그 나\n",
            "1\n",
            "그 누구리 먹는단 말씀이오?\"\n",
            "사초 부인은 영창을 홱 열어젲뜨렸다.\n",
            "늙은가 넋슨 딴 대소를 \n",
            "2\n",
            "그런 대약한 분분을…….\n",
            "독하가탑은서게렇맞고평긴 굉뻘한,모롱에는 뺨치가언뺨까는 웃노복상 추촉\n"
          ]
        }
      ]
    }
  ]
}